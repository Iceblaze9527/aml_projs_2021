{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09944f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import neurokit2 as nk\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from biosppy.signals import ecg\n",
    "import scipy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "X_train_path = 'X_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "\n",
    "sampling_rate = 300\n",
    "threshhold = 0\n",
    "shrinkage = 0.1\n",
    "\n",
    "## val_ratio = 0.1\n",
    "random_state = 29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6179d",
   "metadata": {},
   "source": [
    "## 1. HRV feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(root_path, data_path):\n",
    "    return pd.read_csv(os.path.join(root_path, data_path)).values[:,1:]\n",
    "\n",
    "X_train_raw = data_loading(root_path, X_train_path)\n",
    "y_train_raw = data_loading(root_path, y_train_path).ravel()\n",
    "X_test_raw = data_loading(root_path, X_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe188f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list(matrix):\n",
    "    sequences = list()\n",
    "    for row in matrix:\n",
    "        row = row[~np.isnan(row)]\n",
    "        sequences.append(row)\n",
    "    return sequences\n",
    "\n",
    "def generate_features(X):\n",
    "    c1 = -1\n",
    "    nan = []\n",
    "    H = []\n",
    "    for row in X:\n",
    "        c1 += 1\n",
    "        out = ecg.ecg(signal=row,sampling_rate=sampling_rate, show=False)\n",
    "        \n",
    "        # heartbeat features \n",
    "        heart_rates = out['heart_rate'][~np.isnan(out['heart_rate'])] #heart rate\n",
    "        hr_mean = np.mean(heart_rates)#heart rate mean\n",
    "        if np.isnan(hr_mean):\n",
    "            nan.append(c1)\n",
    "            out_new = np.ones(out['heart_rate'].shape[0]+1)*90 # set a random heartbeat of 90, should not occur that often\n",
    "            hr_mean =  np.mean(out_new) # heart rate mean\n",
    "            hr_median = np.median(out_new) #heart rate median\n",
    "            hr_std = np.std(out_new) #heart rate standart deviation\n",
    "            hr_var = np.var(out_new) #heart rate variance\n",
    "            hr_mad = scipy.stats.median_absolute_deviation(out_new) #heart rate median absloute deviation\n",
    "        else:\n",
    "            hr_median = np.median(heart_rates) #heart rate median\n",
    "            hr_std = np.std(heart_rates) #heart rate standart deviation\n",
    "            hr_var = np.var(heart_rates) #heart beat variance\n",
    "            hr_mad = scipy.stats.median_absolute_deviation(heart_rates) #heart rate median absloute deviation\n",
    "        hr_features = np.array([hr_mean,hr_median,hr_std,hr_var, hr_mad]) #first few features\n",
    "\n",
    "        r_intensities = row[out['rpeaks']]\n",
    "        r_int_mean = np.mean(r_intensities) #mean of the intrnsities\n",
    "        r_int_median = np.median(r_intensities) # median of the intensities\n",
    "        r_int_std = np.std(r_intensities) #stadnard deviation  of the intensities\n",
    "        r_int_var = np.var(r_intensities) #variance of the intensities\n",
    "        r_int_mad = scipy.stats.median_absolute_deviation(r_intensities) #median absolute deviation of the intensities\n",
    "        r_int_features = np.array([r_int_mean,r_int_median,r_int_std,r_int_var, r_int_mad]) #more features\n",
    "        \n",
    "        #RR interval features \n",
    "        r_peaks = out['ts'][out['rpeaks']] \n",
    "        rri = np.diff(r_peaks)*1000 # rr interval in milli seconds\n",
    "        rri_mean = np.mean(rri) #mean of the rr intervals\n",
    "        rri_median = np.median(rri) #median of the rr intervals\n",
    "        rri_std = np.std(rri) #standard deviation of the rr intervals\n",
    "        rri_var = np.var(rri) # variance of the rr intervals\n",
    "        rri_diff = np.absolute(np.diff(rri)) #difference of peaks: out[i] = a[i+1] - a[i]\n",
    "        nn10 = rri_diff[rri_diff>10].shape[0] #amount of peak diff higher than 10\n",
    "        nn20 = rri_diff[rri_diff>20].shape[0] #amount of peak diff higher than 20\n",
    "        nn50 = rri_diff[rri_diff>50].shape[0] #amount of peak diff higher than 50\n",
    "        nn100 = rri_diff[rri_diff>100].shape[0] #amount of peak diff higher than 100\n",
    "        nn200 = rri_diff[rri_diff>200].shape[0] #amount of peak diff higher than 200\n",
    "        nn500 = rri_diff[rri_diff>500].shape[0] #amount of peak diff higher than 500\n",
    "        rri_diff_length = rri_diff.shape[0]\n",
    "        pnn10 = nn10 / rri_diff_length #amount of peak diff higher than 10 compared to the number all differences\n",
    "        pnn20 = nn20 / rri_diff_length #amount of peak diff higher than 20 compared to the number all differences\n",
    "        pnn50 = nn50 / rri_diff_length #amount of peak diff higher than 50 compared to the number all differences\n",
    "        pnn100 = nn100 / rri_diff_length #amount of peak diff higher than 100 compared to the number all differences\n",
    "        pnn200 = nn200 / rri_diff_length #amount of peak diff higher than 200 compared to the number all differences\n",
    "        pnn500 = nn500 / rri_diff_length #amount of peak diff higher than 500 compared to the number all differences\n",
    "        rmssd = np.sqrt(np.mean(rri_diff**2)) #root mean squared\n",
    "        cvsd = rmssd / rri_mean #coefficient of variance\n",
    "        sdsd = np.std(rri_diff) #standard deviation\n",
    "        madnn = scipy.stats.median_absolute_deviation(rri) #median absolute deviation\n",
    "        mcvnn = madnn / rri_median #median coefficient variance\n",
    "           \n",
    "        r_features = np.array([r_int_mean,r_int_median,r_int_std,r_int_var, r_int_mad, rri_mean, rri_median, rri_std, rri_var, nn10, nn20, nn50, nn100, nn200, nn500, pnn10, pnn20, pnn50, pnn100, pnn200, pnn500, rmssd, cvsd, sdsd, madnn, mcvnn]) #even more features\n",
    "        \n",
    "        if np.any(np.isnan(r_features)): #should never be the case\n",
    "            nan.append(c1)\n",
    "            r_features = np.zeros(r_features.shape[0])\n",
    "        \n",
    "        features = np.concatenate((hr_features, r_int_features,r_features), axis=None)\n",
    "        H.append(features)\n",
    "        G = np.asarray(H)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = generate_list(X_train_raw)\n",
    "X_test = generate_list(X_test_raw)\n",
    "\n",
    "X_train = generate_features(X_train)\n",
    "X_test = generate_features(X_test)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)   \n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98740ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = RandomOverSampler(sampling_strategy='minority', shrinkage=shrinkage, random_state=random_state).fit_resample(X_train, y_train_raw)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295999ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_KFold = 5\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [160],\n",
    "    'max_depth': [5,15],\n",
    "    'subsample': [0.9],\n",
    "    'min_child_weight': [5],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'colsample_bylevel': [0.8],\n",
    "    'colsample_bynode': [0.5],\n",
    "    'learning_rate': np.arange(0.15, 0.25, step=0.05),\n",
    "    'reg_alpha': [1e-2,1e-1,1e0]}\n",
    "#  / reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\n",
    "    'verbose': False}\n",
    "\n",
    "xgboost = xgb.XGBClassifier(verbosity = 0, objective='multi:softmax', tree_method='gpu_hist', \n",
    "                            random_state=random_state, gpu_id=0, predictor='gpu_predictor')\n",
    "\n",
    "%time clsf = GridSearchCV(xgboost, xgb_param_grid, scoring='f1_micro', n_jobs=16, cv=num_KFold).fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17630869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estmator: \", clsf.best_estimator_)\n",
    "print(\"Best Score: \", clsf.best_score_)\n",
    "print(\"Feature Importances: \", clsf.best_estimator_.feature_importances_)##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52052a",
   "metadata": {},
   "source": [
    "## 3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06dcc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path = 'y_test_yutong_v26.csv'\n",
    "y_test = clsf.predict(X_test)\n",
    "df_result = pd.DataFrame(data=y_test.astype(int), columns=['y'])\n",
    "df_result.to_csv(path_or_buf=os.path.join(root_path, y_test_path), index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea764d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proj0]",
   "language": "python",
   "name": "conda-env-proj0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
