{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09944f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import neurokit2 as nk\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b331cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "X_train_path = 'X_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "\n",
    "sampling_rate = 300\n",
    "threshhold = 0\n",
    "shrinkage = 0.1\n",
    "\n",
    "val_ratio = 0.1\n",
    "random_state = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b6179d",
   "metadata": {},
   "source": [
    "## 1. HRV feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab5750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(root_path, data_path):\n",
    "    return pd.read_csv(os.path.join(root_path, data_path)).values[:,1:]\n",
    "\n",
    "X_train_raw = data_loading(root_path, X_train_path)\n",
    "y_train_raw = data_loading(root_path, y_train_path).ravel()\n",
    "X_test_raw = data_loading(root_path, X_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe188f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hrv_analysis(record, peaks):\n",
    "    time_domain = nk.hrv_time(peaks, sampling_rate=sampling_rate)\n",
    "    \n",
    "    spen, _ = nk.entropy_spectral(record)\n",
    "    rr, _ = nk.complexity_rr(record)\n",
    "    slope, _ = nk.fractal_psdslope(record, method='hasselman2013')#\n",
    "    \n",
    "    hrv_features = np.array([\n",
    "        time_domain[\"HRV_MeanNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_SDNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_MadNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_RMSSD\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_SDSD\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_MedianNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_CVNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_CVSD\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_MCVNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_IQRNN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_pNN50\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_pNN20\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_TINN\"].to_numpy()[0],\n",
    "        time_domain[\"HRV_HTI\"].to_numpy()[0],\n",
    "        spen,\n",
    "        rr,\n",
    "        slope\n",
    "    ]).reshape(-1)\n",
    "    \n",
    "    if True in np.isnan(hrv_features):\n",
    "        return None\n",
    "    else: \n",
    "        return hrv_features\n",
    "\n",
    "def ecg_analysis(record, rpeaks_time):\n",
    "    def remove_nans(*data):\n",
    "        data = [np.array(clip) for clip in data]\n",
    "        nonnan_idxs = list(map(lambda x: np.argwhere(~np.isnan(x)).ravel(), data))\n",
    "        nonnan_idxs = reduce(np.intersect1d, nonnan_idxs)\n",
    "        \n",
    "        data_nonnan = tuple(map(lambda x: x[nonnan_idxs].astype(int), data))\n",
    "        return data_nonnan\n",
    "    \n",
    "    def stats(data):\n",
    "        mean = np.nanmean(data)\n",
    "        std = np.nanstd(data, ddof=1)\n",
    "        med = np.median(data)\n",
    "        maxi = np.amax(data)\n",
    "        mini = np.amin(data)\n",
    "        \n",
    "        return mean, std, med, maxi, mini, maxi-mini, med-mean\n",
    "    \n",
    "#     def get_baseline(record, p_off, r_on):##\n",
    "#         baselines = []\n",
    "        \n",
    "#         for start1, end1 in zip(p_off, r_on):\n",
    "#             if start1 < end1:\n",
    "#                 clip = record[start1:end1+1]\n",
    "#                 baselines.append(np.nanmean(clip))\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#         return np.array(baselines)\n",
    "    \n",
    "    get_qr_ratio = lambda x: np.sign(x) * x**2\n",
    "    \n",
    "    def get_net_qrs_t_cord(record, r_on, r_off, baselines, tpeaks_amp):\n",
    "        net_qrs = []\n",
    "        \n",
    "        for on, off in zip(r_on, r_off):\n",
    "            net_qrs.append(np.sum(record[on:off+1] - baselines))\n",
    "        \n",
    "        prod = np.array(net_qrs) * tpeaks_amp\n",
    "        return np.sign(prod) * np.sqrt(np.abs(prod))\n",
    "    \n",
    "    signals, waves = nk.ecg_delineate(record, rpeaks=rpeaks_time, sampling_rate=sampling_rate, method='dwt')\n",
    "    rr_int = nk.ecg_rate(rpeaks_time, sampling_rate=sampling_rate)\n",
    "     \n",
    "    ## interval features (index list) so this somehow does scaling\n",
    "    ## heartrate = ecg_rate\n",
    "    ppeaks_time, qpeaks_time, rpeaks_time, speaks_time, tpeaks_time, p_on, p_off, r_on, r_off, t_on, t_off, rr_int = \\\n",
    "    remove_nans(waves['ECG_P_Peaks'], waves['ECG_Q_Peaks'], rpeaks_time, waves['ECG_S_Peaks'], waves['ECG_T_Peaks'], \n",
    "                waves['ECG_P_Onsets'], waves['ECG_P_Offsets'], \n",
    "                waves['ECG_R_Onsets'], waves['ECG_R_Offsets'], \n",
    "                waves['ECG_T_Onsets'], waves['ECG_T_Offsets'], rr_int)\n",
    "\n",
    "    pr_int = r_on - p_on\n",
    "    qrs_comp = r_off - r_on\n",
    "    qtc = (t_off - r_on) / np.sqrt(rr_int)\n",
    "    pwav = p_off - p_on\n",
    "    rwp_int = rpeaks_time - r_on\n",
    "    ## q_int\n",
    "    \n",
    "    ##rr_int_stats is already computed\n",
    "    pr_int_stats, qrs_comp_stats, qtc_stats, pwav_stats, rwp_int_stats = \\\n",
    "    tuple(map(lambda x: stats(x), [pr_int, qrs_comp, qtc, pwav, rwp_int]))\n",
    "    \n",
    "    ## amplitude features\n",
    "#     baselines = get_baseline(record, p_off, r_on)# pr_seg = r_on - p_off # t_off, p_on\n",
    "    baselines = 0\n",
    "    \n",
    "    ppeaks_amp, qpeaks_amp, rpeaks_amp, speaks_amp, tpeaks_amp = \\\n",
    "    tuple(map(lambda x: record[x] - baselines, [ppeaks_time, qpeaks_time, rpeaks_time, speaks_time, tpeaks_time]))\n",
    "    \n",
    "    qr_ratio = get_qr_ratio(qpeaks_amp / rpeaks_amp)\n",
    "    st_seg = record[r_off] - baselines ## j60=18 or j80=24, also progressive features\n",
    "    net_qrs_t_cord = get_net_qrs_t_cord(record, r_on, r_off, baselines, tpeaks_amp)\n",
    "    \n",
    "    ppeaks_stats, rpeaks_stats, speaks_stats, tpeaks_stats, qr_ratio_stats, st_seg_stats, net_qrs_t_cord_stats = \\\n",
    "    tuple(map(lambda x: stats(x), [ppeaks_amp, rpeaks_amp, speaks_amp, tpeaks_amp, qr_ratio, st_seg, net_qrs_t_cord]))\n",
    "    \n",
    "    ecg_features = np.array([\n",
    "        *pr_int_stats,\n",
    "        *qrs_comp_stats,\n",
    "        *qtc_stats,\n",
    "        *pwav_stats,\n",
    "        *rwp_int_stats,\n",
    "        *ppeaks_stats,\n",
    "        *rpeaks_stats,\n",
    "        *speaks_stats,\n",
    "        *tpeaks_stats,\n",
    "        *qr_ratio_stats,\n",
    "        *st_seg_stats,\n",
    "        *net_qrs_t_cord_stats,\n",
    "    ]).reshape(-1)\n",
    "    \n",
    "    if True in np.isnan(ecg_features):\n",
    "        return None\n",
    "    else:\n",
    "        return ecg_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d632d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_artifacts(record_cleaned, rpeaks_time, threshhold):\n",
    "    quality = nk.ecg_quality(record_cleaned, rpeaks = rpeaks_time, sampling_rate=sampling_rate, method='averageQRS')#\n",
    "\n",
    "    identifiers = np.where(quality > threshhold, 1, 0)\n",
    "    \n",
    "    if 0 not in identifiers:\n",
    "        return record_cleaned\n",
    "    \n",
    "    diffs = np.diff(identifiers)\n",
    "    starts = (np.argwhere(diffs == 1) + 1).ravel()\n",
    "    stops = (np.argwhere(diffs == -1) + 1).ravel()\n",
    "\n",
    "    if identifiers[0] == 1:\n",
    "        starts = np.concatenate(([0], starts), axis = None)\n",
    "    if identifiers[-1] == 1:\n",
    "        stops = np.concatenate((stops, [len(identifiers)]), axis = None)\n",
    "    \n",
    "    assert stops.shape == starts.shape\n",
    "    intvs = stops - starts\n",
    "    assert intvs.all() >= 0\n",
    "    max_start = starts[intvs==np.amax(intvs)]\n",
    "    max_end = stops[intvs==np.amax(intvs)]\n",
    "    \n",
    "    return record_cleaned[max_start[0]:max_end[0]]\n",
    "\n",
    "def feature_extraction(X_raw):##\n",
    "    X = []\n",
    "    bad_idxs = []\n",
    "    \n",
    "    for record_idx, record_raw in enumerate(X_raw):\n",
    "        record_raw = record_raw[~np.isnan(record_raw)]\n",
    "        record_cleaned = nk.ecg_clean(record_raw, sampling_rate=sampling_rate, method='biosppy')#\n",
    "        \n",
    "        _, info = nk.ecg_peaks(record_cleaned, sampling_rate=sampling_rate, correct_artifacts=True)#\n",
    "        rpeaks_time = info['ECG_R_Peaks']\n",
    "        if np.any(np.diff(rpeaks_time) <= 0):\n",
    "            bad_idxs.append(record_idx)\n",
    "            continue\n",
    "        \n",
    "        record_cleaned = remove_artifacts(record_cleaned, info['ECG_R_Peaks'], threshhold=threshhold)\n",
    "        \n",
    "        peaks, info = nk.ecg_peaks(record_cleaned, sampling_rate=sampling_rate, correct_artifacts=True)\n",
    "        rpeaks_time = info['ECG_R_Peaks']\n",
    "        if np.any(np.diff(rpeaks_time) <= 0):\n",
    "            bad_idxs.append(record_idx)\n",
    "            continue\n",
    "        \n",
    "        hrv_features = hrv_analysis(record_raw, peaks)\n",
    "        if hrv_features is None:\n",
    "            bad_idxs.append(record_idx)\n",
    "            continue\n",
    "        \n",
    "        ecg_features = ecg_analysis(record_cleaned, rpeaks_time)\n",
    "        if ecg_features is None:\n",
    "            bad_idxs.append(record_idx)\n",
    "            continue\n",
    "        \n",
    "        features = np.concatenate((hrv_features,ecg_features))\n",
    "        X.append(features)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    \n",
    "    return X, bad_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bcbd3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time X_train_all, bad_idxs = feature_extraction(X_train_raw)\n",
    "y_train_all = np.delete(y_train_raw, bad_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time X_test, bad_idxs_test = feature_extraction(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=val_ratio, random_state=random_state, shuffle=True)\n",
    "X_train, y_train = RandomOverSampler(sampling_strategy='minority', shrinkage=shrinkage, random_state=random_state).fit_resample(X_train_all, y_train_all)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f88b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_KFold = 5\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [120], #np.arange(100, 151, step=5),\n",
    "    'max_depth': [5], #np.arange(3,8),\n",
    "    'subsample': [0.9],\n",
    "    'min_child_weight': [5],\n",
    "    'colsample_bytree': np.arange(0.5, 0.9, step=0.1),\n",
    "    'colsample_bylevel': np.arange(0.5, 0.9, step=0.1),\n",
    "    'colsample_bynode': np.arange(0.5, 0.9, step=0.1),\n",
    "    'learning_rate': [0.15]#np.arange(0.05, 0.3, step=0.05)\n",
    "}\n",
    "# reg_alpha / reg_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\n",
    "    'verbose': False}\n",
    "\n",
    "xgboost = xgb.XGBClassifier(verbosity = 0, objective='multi:softmax', tree_method='gpu_hist', \n",
    "                            random_state=random_state, gpu_id=0, predictor='gpu_predictor')\n",
    "\n",
    "%time clsf = GridSearchCV(xgboost, xgb_param_grid, scoring='f1_micro', n_jobs=8, cv=num_KFold).fit(X_train, y_train, **fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Estmator: \", clsf.best_estimator_)\n",
    "print(\"Best Score: \", clsf.best_score_)\n",
    "print(\"Feature Importances: \", clsf.best_estimator_.feature_importances_)##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52052a",
   "metadata": {},
   "source": [
    "## 3. Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2dcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = 3 + np.zeros(X_test_raw.shape[0])\n",
    "y_test[~np.isin(np.arange(len(y_test)), bad_idxs_test)] = clsf.predict(X_test) ## bad_idxs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_path = 'y_test_yutong_v19.csv'\n",
    "df_result = pd.DataFrame(data=y_test.astype(int), columns=['y'])\n",
    "df_result.to_csv(path_or_buf=os.path.join(root_path, y_test_path), index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5da1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proj0]",
   "language": "python",
   "name": "conda-env-proj0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
