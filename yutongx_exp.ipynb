{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raised-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from RegressorEnsemble import RegressorEnsemble\n",
    "from random import gauss, expovariate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-senior",
   "metadata": {},
   "source": [
    "## 0. Parameters\n",
    "\n",
    "### 0.1 Global Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dress-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "X_train_path = 'X_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "# y_test_path = 'y_test_yutong_v10.csv'\n",
    "ensemble_path = \"y_test_yutong_v14.csv\"\n",
    "\n",
    "val_size = 10\n",
    "random_state = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-monster",
   "metadata": {},
   "source": [
    "### 0.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescribed-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 200# np.arange(175,251)## about 200 real features\n",
    "l1_lambda = 0.2\n",
    "max_features = 25\n",
    "\n",
    "n_estimators = 100# np.arange(100,176)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-financing",
   "metadata": {},
   "source": [
    "### 0.3 Regresion & Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "assisted-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembleSize = 10\n",
    "paramRandDistributions = { #TODO: still need to put found optimal values as expectations here\n",
    "    'C': lambda: gauss(101, 1),\n",
    "    'gamma': lambda: gauss(4e-3, 3e-4),\n",
    "    \"epsilon\": lambda: 0.1} #expovariate(9) #TODO: maybe uniform distribution between some values is better suited for epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-necessity",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adopted-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_raw(root_path, data_path):\n",
    "    return pd.read_csv(os.path.join(root_path, data_path)).values[:,1:]\n",
    "\n",
    "X_train_raw = data_raw(root_path, X_train_path)\n",
    "X_test_raw = data_raw(root_path, X_test_path)\n",
    "y_train = data_raw(root_path, y_train_path).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-timber",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling & Preprocessing\n",
    "\n",
    "### 2.1 Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brutal-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(X_raw):\n",
    "    imp_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    return imp_med.fit_transform(X_raw)\n",
    "\n",
    "X_train_raw = imputation(X_train_raw)\n",
    "X_test_raw = imputation(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-episode",
   "metadata": {},
   "source": [
    "### 2.2 Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "occasional-player",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected 209 out of 832 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:284: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means ** 2)\n",
      "/home/leona/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "def feature_selection_fabian(X_train, y_train): \n",
    "    normalizedX_train = StandardScaler().fit_transform(X_train)\n",
    "    \n",
    "    lasso = Lasso(alpha=l1_lambda, random_state=random_state).fit(normalizedX_train, y_train)\n",
    "    selectionModel = SelectFromModel(lasso, prefit=True, max_features=max_features)\n",
    "    \n",
    "    return selectionModel.get_support(indices=True)\n",
    "\n",
    "def feature_selection_yutong(X_train, y_train):\n",
    "    kbest = SelectKBest(score_func = f_regression, k=num_features).fit(X_train, y_train)\n",
    "    \n",
    "    return kbest.get_support(indices=True)\n",
    "\n",
    "def feature_selection(X_test, X_train, y_train):\n",
    "    selectedFeaturesFabian = feature_selection_fabian(X_train, y_train)\n",
    "    selectedFeaturesYutong = feature_selection_yutong(X_train, y_train)\n",
    "    \n",
    "    selectedIdxs = selectedFeaturesYutong\n",
    "    selectedIdxs = np.union1d(selectedFeaturesFabian, selectedFeaturesYutong)\n",
    "    print(f\"selected {len(selectedIdxs)} out of {X_train.shape[1]} features\")\n",
    "    \n",
    "    selectedX_train = X_train[:, selectedIdxs]\n",
    "    selectedX_test = X_test[:, selectedIdxs]\n",
    "    \n",
    "    return selectedX_test, selectedX_train\n",
    "\n",
    "X_test_raw, X_train_raw = feature_selection(X_test_raw, X_train_raw, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-sampling",
   "metadata": {},
   "source": [
    "### 2.3 Outlier Detection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liberal-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detection(X_raw, y, n_estimators):\n",
    "    iso = IsolationForest(n_estimators = n_estimators, random_state=random_state).fit_predict(X_raw)\n",
    "    return X_raw[iso == 1], y[iso == 1]\n",
    "\n",
    "# def train_val_split(X_train, y_train, val_size):\n",
    "#     return train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)\n",
    "\n",
    "# X_train_raw, X_val_raw, y_train, y_val = train_val_split(X_train_raw, y_train, val_size=val_size)\n",
    "X_train_raw, y_train = outlier_detection(X_train_raw, y_train, n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-collar",
   "metadata": {},
   "source": [
    "### 2.4 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ethical-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train_raw)\n",
    "# X_val = StandardScaler().fit_transform(X_val_raw)\n",
    "X_test = StandardScaler().fit_transform(X_test_raw)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-reception",
   "metadata": {},
   "source": [
    "## 3. Ensemble with perturbed parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "after-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegressorEnsemble.RegressorEnsemble at 0x7f9556dd7460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPerturbedSvrs(paramRandDistributions, nSvrs):\n",
    "    \"\"\"paramGrid: dict where each key has a callable that will sample values from a random distribution as value.\"\"\"\n",
    "    svrs = []\n",
    "    for i in range(nSvrs):\n",
    "        sampledParams = {key: param() for key, param in paramRandDistributions.items()}\n",
    "        svrs.append(SVR(**sampledParams))\n",
    "    return svrs\n",
    "\n",
    "ensemble = RegressorEnsemble(getPerturbedSvrs(paramRandDistributions, ensembleSize))\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-merchandise",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58354c2b",
   "metadata": {},
   "source": [
    "y_val_pred = ensemble.predict(X_val)\n",
    "print(\"Val R2 Score: \", r2_score(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ae80d0",
   "metadata": {},
   "source": [
    "## 5. Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a66214",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ensemble.predict(X_test)\n",
    "\n",
    "df_result = pd.DataFrame(data = y_test_pred, columns=['y'])\n",
    "df_result.to_csv(path_or_buf=os.path.join(root_path, ensemble_path), index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b571b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
