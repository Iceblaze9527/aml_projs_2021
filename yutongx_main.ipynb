{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26924d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer#, IterativeImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, f_regression## exp needed!\n",
    "\n",
    "from sklearn.ensemble import IsolationForest## exp needed!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer## exp needed!\n",
    "\n",
    "from sklearn.svm import SVR## exp needed!\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV## exp needed!\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b07f2d",
   "metadata": {},
   "source": [
    "## 0. Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c4abf",
   "metadata": {},
   "source": [
    "### 0.1 Global Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "448e1cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './'\n",
    "X_train_path = 'X_train.csv'\n",
    "X_test_path = 'X_test.csv'\n",
    "y_train_path = 'y_train.csv'\n",
    "y_test_path = 'y_test_yutong_v3.csv'\n",
    "\n",
    "val_size = 50\n",
    "random_state = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061adcd",
   "metadata": {},
   "source": [
    "### 0.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51a28467",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 150## about 200 real features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f448301",
   "metadata": {},
   "source": [
    "#### 0.2.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2139389",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "contamination = 'auto'## not tuned yet\n",
    "max_features = 1.0## not tuned yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e62513",
   "metadata": {},
   "source": [
    "### 0.3 Regresion\n",
    "#### 0.3.1 SVR: Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0962f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_grid = {\n",
    "    'C': [1, 10, 100, 1000], \n",
    "    'gamma': [1, 0.1, 0.01, 0.001]}## good start, as a ref to random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3324de6",
   "metadata": {},
   "source": [
    "### 0.4 Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4d1ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_KFold = 10## better than 5-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d5388",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05b589f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_raw(root_path, data_path):\n",
    "    return pd.read_csv(os.path.join(root_path, data_path)).values[:,1:]\n",
    "\n",
    "X_train_raw = data_raw(root_path, X_train_path)\n",
    "X_test_raw = data_raw(root_path, X_test_path)\n",
    "y_train = data_raw(root_path, y_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b55d5",
   "metadata": {},
   "source": [
    "## 2. Data Wrangling & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f04fcb3",
   "metadata": {},
   "source": [
    "### 2.1 Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c21a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_imp(X_raw):\n",
    "    imp_med = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    return imp_med.fit_transform(X_raw)\n",
    "\n",
    "def knn_imp(X_raw):##to-do, still a comp intensive methods and suffers from curse of dimensionality and outliers\n",
    "    pass\n",
    "\n",
    "def mice_imp(X_raw):#use after fea sel! this method is comp expensive, and is an unstable implementation based on docs\n",
    "    imp_mice = IterativeImputer(missing_values=np.nan, initial_strategy='median')\n",
    "    return imp_mice.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a62956f",
   "metadata": {},
   "source": [
    "> Remark: The median imputation is too naive to be proper in our situation. The best ones, I believe, are regression/interpolation methods like mice but mice suffers from high dims. Also, there may be no sklearn implementation for other possible methods. We may consider doing feature selection b4 this step but beware there can be problems of preprocessing orders that Fabian mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc5fdd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = median_imp(X_train_raw)\n",
    "X_test_raw = median_imp(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccc3a08",
   "metadata": {},
   "source": [
    "### 2.2 Feature Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059a2d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_sel(X_raw, y, score_func, num_features):\n",
    "    return SelectKBest(score_func = score_func, k=num_features).fit(X_raw, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646078fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leona/anaconda3/envs/proj0/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:284: RuntimeWarning: invalid value encountered in sqrt\n",
      "  X_norms = np.sqrt(row_norms(X.T, squared=True) - n_samples * X_means ** 2)\n",
      "/home/leona/anaconda3/envs/proj0/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
      "  correlation_coefficient /= X_norms\n"
     ]
    }
   ],
   "source": [
    "selector = feat_sel(X_train_raw, y_train, f_regression, num_features)\n",
    "\n",
    "X_train_raw = selector.transform(X_train_raw)\n",
    "X_test = selector.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a7edb",
   "metadata": {},
   "source": [
    "> Remark: most recent exps show that compared to mutual_info, f_regression are insensitive (if chosen properly) to #features and #estimators for isolation forests, and produce better results. We can check the scores to determine #features to choose. My lucky range falls on 100-200, which is similar to the actual #features mentioned during the exercise session.\n",
    "\n",
    "> there are even more complex feature sel criteria like cond infomax which does more than f_reg and mi. We need extra lib for this if we wanna try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916de77a",
   "metadata": {},
   "source": [
    "### 2.3 Outlier Detection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6017bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(X_train, y_train, val_size):\n",
    "    return train_test_split(X_train, y_train, test_size=val_size, random_state=random_state)\n",
    "\n",
    "def iforest(X_raw, y, n_estimators):## param control\n",
    "    iso = IsolationForest(n_estimators = n_estimators, random_state=random_state).fit_predict(X_raw)\n",
    "    return X_raw[np.where(iso==1)], y[np.where(iso==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5645fb",
   "metadata": {},
   "source": [
    "> Remark: isolation forest is an unsupervised, log-time outlier detection method which is extremely suitable for high dim cases so I prefer it here. We can also try out dbscan, lof, rrcf since we've done feature selection and free from high dim (but 200 features is still not sth easy...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1b1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_val, y_train, y_val = train_val_split(X_train_raw, y_train, val_size)\n",
    "\n",
    "X_train, y_train = iforest(X_train_raw, y_train, n_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c911558",
   "metadata": {},
   "source": [
    "> Remark: sth nuanced here: do val set need outlier detection? my answer is no. Val set should mimic the behavior of the test set which CAN contain outliers, and we do not expect our model to perform well on outliers anyway. But current implementation of gridsearch are using cleaned val sets, and i am not sure if this introduces problems..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ddd8ce",
   "metadata": {},
   "source": [
    "### 2.4 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b611ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_val = StandardScaler().fit_transform(X_val)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461ca61",
   "metadata": {},
   "source": [
    "> Remark: Scaling is important for svr. Besides std scaler we can also try out QuantileTransformer which can deal with outliers, but I believe scaling would not affect much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d29fe",
   "metadata": {},
   "source": [
    "## 3. Regression & Param Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11966375",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "reg = GridSearchCV(svr, svr_param_grid, scoring='r2', cv=num_KFold).fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de3c9ef",
   "metadata": {},
   "source": [
    "> Remark: I like SVR because it is non-linear and has infinite representiveness if params are fine-tuned as far as I know. Also diff kernel funcs can produce similar results so all we have to do is to tune C and gamma for rbf kernel. There are a bunch of other reg methods to explore but I prefer to stick to SVR at the moment.\n",
    "\n",
    "> for model sel we can also try random search here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "576310a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.01)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92d45d2",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcd724da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6913236293776486\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = reg.predict(X_val)\n",
    "\n",
    "score = r2_score(y_val, y_val_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3aa8d",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c44f851",
   "metadata": {},
   "source": [
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "df_result = pd.DataFrame(data = y_test_pred, columns=['y'])\n",
    "df_result.to_csv(path_or_buf=os.path.join(root_path,y_test_path), index_label='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3025b455",
   "metadata": {},
   "source": [
    "> Other to-dos: order of preprocessing, ensemble, pipeline, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af7c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5bc516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354fe6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proj0] *",
   "language": "python",
   "name": "conda-env-proj0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
