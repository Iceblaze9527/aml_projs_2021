{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ffb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from testdataset import get_loader\n",
    "from architectures import UNet\n",
    "from testoperation import run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d970f",
   "metadata": {},
   "source": [
    "## 1. Global Variables and Backend Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a86162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = './_data/test.pkl'\n",
    "save_dir = './_saved_models'\n",
    "result_dir = './_results'\n",
    "\n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b67b6",
   "metadata": {},
   "source": [
    "## 2. GPU Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_manager(model):\n",
    "    device_cnt = torch.cuda.device_count()\n",
    "    if device_cnt > 0:\n",
    "        if device_cnt == 1:\n",
    "            print('Only 1 GPU is available.')\n",
    "        else:\n",
    "            print(f\"{device_cnt} GPUs are available.\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print('Only CPU is available.')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45869330",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a154d",
   "metadata": {},
   "source": [
    "### 3.1. About Padding:\n",
    "when using valid padding, the output size may not match input size, thus zero padding the input is needed,\n",
    "\n",
    "the sizes should be calculated in advance based on the network structure, in our case (default UNet):\n",
    "- `input_size = 204`, \n",
    "- `pad_size = (input_size - output_size)//2`\n",
    "\n",
    "if same padding then `pad_size = 0`\n",
    "\n",
    "### 3.2. UNet Args:\n",
    "- **in_channels (int)**: number of input channels\n",
    "- **n_classes (int)**: number of output channels\n",
    "- **depth (int)**: depth of the network\n",
    "- **wf (int)**: number of filters in the first layer is `2**wf`\n",
    "- **padding (bool)**: if True, apply padding such that the input shape is the same as the output. This may introduce artifacts\n",
    "- **batch_norm (bool)**: Use BatchNorm after layers with an activation function\n",
    "- **up_mode (str)**: one of 'upconv' or 'upsample'. 'upconv' will use transposed convolutions for learned upsampling. 'upsample' will use bilinear upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = {\n",
    "    'pad_size': 46,\n",
    "    'output_size': 112,## plz use even single values, odd size and rectangles are not taken care of!\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'in_channels':1,\n",
    "    'n_classes':2,\n",
    "    'depth':4,## 4 at maximum\n",
    "    'wf':5,\n",
    "    'padding':False,\n",
    "    'batch_norm':False,\n",
    "    'up_mode':'upconv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871188f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'dataloader': get_loader(test_path, resize),\n",
    "    'model': gpu_manager(UNet(**model_params)),\n",
    "    'ckpt_path': os.path.join(save_dir, 'checkpoint33.tar.gz')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9eeea3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soft_preds = run(**run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53c1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def save_zipped_pickle(obj, filename):\n",
    "    with gzip.open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc93b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_zipped_pickle(soft_preds, os.path.join(result_dir, 'soft_pred_ckpt33.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aedcce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:proj3] *",
   "language": "python",
   "name": "conda-env-proj3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
