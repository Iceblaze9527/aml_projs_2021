{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from dataset import get_loader\n",
    "from architectures import UNet\n",
    "from losses import FocalLoss\n",
    "from operation import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Global Variables and Backend Fixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_path = './_data/train.pkl'\n",
    "log_dir = './_logs/'\n",
    "save_dir = './_saved_models'\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "torch.manual_seed(random_state)\n",
    "torch.cuda.manual_seed_all(random_state)\n",
    "torch.backends.cudnn.deterministic = True \n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU Mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_manager(model):\n",
    "    device_cnt = torch.cuda.device_count()\n",
    "    if device_cnt > 0:\n",
    "        if device_cnt == 1:\n",
    "            print('Only 1 GPU is available.')\n",
    "        else:\n",
    "            print(f\"{device_cnt} GPUs are available.\")\n",
    "            model = torch.nn.DataParallel(model)\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print('Only CPU is available.')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. About Padding:\n",
    "when using valid padding, the output size may not match input size, thus zero padding the input is needed,\n",
    "\n",
    "the sizes should be calculated in advance based on the network structure, in our case (default UNet):\n",
    "- `input_size = 204`, \n",
    "- `pad_size = (input_size - output_size)//2`\n",
    "\n",
    "the corresponding output size is `116`, so we still need to slice it into `112**2`\n",
    "\n",
    "if same padding then `pad_size = 0`\n",
    "\n",
    "### 3.2. UNet Args:\n",
    "- **in_channels (int)**: number of input channels\n",
    "- **n_classes (int)**: number of output channels\n",
    "- **depth (int)**: depth of the network\n",
    "- **wf (int)**: number of filters in the first layer is `2**wf`\n",
    "- **padding (bool)**: if True, apply padding such that the input shape is the same as the output. This may introduce artifacts\n",
    "- **batch_norm (bool)**: Use BatchNorm after layers with an activation function\n",
    "- **up_mode (str)**: one of 'upconv' or 'upsample'. 'upconv' will use transposed convolutions for learned upsampling. 'upsample' will use bilinear upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = {\n",
    "    'pad_size': 46,\n",
    "    'output_size': 112,## plz use even single values, odd size and rectangles are not taken care of!\n",
    "}\n",
    "\n",
    "augs = {\n",
    "    'rotate':(-15,15),\n",
    "    'scale':(0.85,1.15),\n",
    "    'translate':(0.15,0.15),\n",
    "    'shear':(-10,10,-10,10),\n",
    "}\n",
    "\n",
    "data_params = {\n",
    "    'val_size': 1,\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 4,\n",
    "}\n",
    "\n",
    "model_params = {\n",
    "    'in_channels':1,\n",
    "    'n_classes':2,\n",
    "    'depth':4,## 4 at maximum\n",
    "    'wf':5,\n",
    "    'padding':False,\n",
    "    'batch_norm':False,\n",
    "    'up_mode':'upconv',\n",
    "}\n",
    "\n",
    "optim_params = {\n",
    "    'lr':3e-4,\n",
    "    'betas':(0.9, 0.999),\n",
    "    'eps':1e-08,\n",
    "    'weight_decay':1e-4,\n",
    "}\n",
    "\n",
    "loss_params = {\n",
    "    'reduction':'none',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(save_dir, 'checkpoint0.tar.gz'))\n",
    "\n",
    "model = gpu_manager(UNet(**model_params))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), **optim_params)\n",
    "optim.load_state_dict(checkpoint['optim_state_dict'])\n",
    "\n",
    "print(checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'dataloader': get_loader(train_path, resize, augs, **data_params),\n",
    "    'model': model,\n",
    "    'optim': optim,\n",
    "    'scheduler': checkpoint['scheduler'],\n",
    "    'criterion': torch.nn.CrossEntropyLoss(**loss_params),\n",
    "    'epochs': 300 - checkpoint['epoch'],\n",
    "    'log_path': os.path.join(log_dir, 'log_33/'),\n",
    "    'save_path': os.path.join(save_dir, 'checkpoint33.tar.gz')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(**run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
